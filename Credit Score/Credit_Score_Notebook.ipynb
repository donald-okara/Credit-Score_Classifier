{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                            Credit Score Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plotly\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Libraries imported successfully....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "df =  pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(\"Data imported successfully....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Payment_Behaviour', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of missing data points per column in Complaints_df\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "# look at the # of missing points\n",
    "missing_values_count\n",
    "\n",
    "##Relevant Null vallues dropped in mining via query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing data handling plan\n",
    "1. Name: We wont be using this as a feature \n",
    "2. Monthly inhand salary,Number of delayed payment, Num credit inquiries, Amount invested monthly, Monthly balance : all set to zero.\n",
    "3. Type of Loan: will be split into one hot and null values will sort theselves out.\n",
    "4. Credit history age will be feature engineered into numerics and null will be set to zero\n",
    "\n",
    "There is data for eight months of the year for each client. Upon research, I found that credit score is not dependant on the previous month hence each entry in the dataset can and will be used independently. Trying a time series trick would be overfitting.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric values handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit history age to months\n",
    "def age_to_months(age_str):\n",
    "    if pd.isna(age_str) or age_str == '':\n",
    "        return float('nan')\n",
    "    age_list = age_str.split()\n",
    "    years = int(age_list[0])\n",
    "    months = int(age_list[3])\n",
    "    total_months = years * 12 + months\n",
    "    return total_months\n",
    "\n",
    "df['Credit_History_Age'] = df['Credit_History_Age'].apply(age_to_months)\n",
    "\n",
    "numeric_cols = ['Annual_Income','Monthly_Inhand_Salary','Num_Bank_Accounts','Num_Credit_Card','Interest_Rate','Num_of_Loan','Delay_from_due_date','Num_of_Delayed_Payment','Changed_Credit_Limit','Num_Credit_Inquiries','Outstanding_Debt','Credit_Utilization_Ratio','Credit_History_Age','Total_EMI_per_month','Amount_invested_monthly','Monthly_Balance']\n",
    "categorical_cols = ['Occupation','Credit_Mix','Payment_of_Min_Amount']\n",
    "\n",
    "\n",
    "#Cleaning up underscored columns\n",
    "\n",
    "# remove '_' from values in specified columns and convert to float\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_cols:\n",
    "    df[col] = df[col].replace('_', '')\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# print the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Categorical values handling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Segregate into high paying, medium and low paying' and use ordinal encoding\n",
    "2. Month to be transformed into ordinal encoding\n",
    "3. Separate types of loans and Payment_Behaviour by commas and count number of loans\n",
    "4. Transform Credit Mix and Payment_of_Min_Amount with ordinal encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annual salaries feature engineering\n",
    "\n",
    "# Define the income thresholds for each category\n",
    "income_bins = [0, 30000, 70000, float('inf')]\n",
    "income_labels = ['Low Income', 'Medium Income', 'High Income']\n",
    "\n",
    "# Segregate the annual income into categories using pandas cut() function\n",
    "df['Income_Category'] = pd.cut(df['Annual_Income'], bins=income_bins, labels=income_labels)\n",
    "\n",
    "# Plot the frequency distribution of each income category using a bar plot\n",
    "df['Income_Category'].value_counts().plot(kind='bar', rot=0)\n",
    "\n",
    "# Set the axis labels and title\n",
    "plt.xlabel('Income_Category')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of Annual Income by Category')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['Month','Occupation','Type_of_Loan','Credit_Mix','Payment_of_Min_Amount','Payment_Behaviour','Credit_Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = df['Payment_of_Min_Amount'].value_counts()\n",
    "print(unique_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot for each numeric column by \"Credit_Score\"\n",
    "for col in numeric_cols:\n",
    "    plt.figure()\n",
    "    sns.boxplot(x='Credit_Score', y=col, data=df)\n",
    "    plt.title(col)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot for each categorical column by \"Credit_Score\"\n",
    "# Iterate over each categorical column and create a bar plot\n",
    "for col in categorical_cols:\n",
    "    # Group the DataFrame by 'Credit_Score' and the current categorical column\n",
    "    grouped = df.groupby(['Credit_Score', col]).size().unstack()\n",
    "    \n",
    "    # Normalize the data to convert counts to proportions\n",
    "    grouped = grouped.div(grouped.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Create the bar plot\n",
    "    grouped.plot(kind='bar', stacked=True)\n",
    "    plt.title(col)\n",
    "    plt.xlabel('Credit_Score')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Define the features and label\n",
    "features = ['Monthly_Inhand_Salary', 'Num_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance','Credit_Mix', 'Payment_of_Min_Amount']\n",
    "label = 'Credit_Score'\n",
    "\n",
    "# Convert the label column to ordinal categories\n",
    "label_encoder = OrdinalEncoder()\n",
    "y = label_encoder.fit_transform(df[label].values.reshape(-1, 1))\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Categorical and numerical cols\n",
    "cat_cols = ['Credit_Mix', 'Payment_of_Min_Amount']\n",
    "num_cols = ['Monthly_Inhand_Salary', 'Num_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance']\n",
    "\n",
    "# Define a pipeline for numeric columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define a pipeline for categorical columns\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a ColumnTransformer to apply the pipeline to the numeric and categorical columns\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    ('cat', cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "# Fit the preprocessor to the training data and transform both the training and test data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print('Training Set: %d, Test Set: %d \\n' % (len(X_train), len(X_test)))\n",
    "\n",
    "# Print the transformed DataFrame\n",
    "print(\"X_train_Transformed /n\",X_train_transformed)\n",
    "print(\"X_test_Transformed /n\",X_test_transformed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier#\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#mcm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "lr_model = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=10000).fit(X_train_transformed, y_train)\n",
    "kn_model = KNeighborsClassifier().fit(X_train_transformed, y_train)\n",
    "dt_model = DecisionTreeClassifier().fit(X_train_transformed, y_train)\n",
    "rf_model = RandomForestClassifier().fit(X_train_transformed, y_train)\n",
    "nb_model = GaussianNB().fit(X_train_transformed, y_train)\n",
    "ab_model = AdaBoostClassifier().fit(X_train_transformed, y_train)\n",
    "#svc_model = SVC().fit(X_train_transformed,y_train)\n",
    "\n",
    "\n",
    "models = [lr_model, kn_model, dt_model, rf_model, ab_model, nb_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_func(curr_model):\n",
    "    print('\\n Current model is: \\n', curr_model)\n",
    "    predictions = curr_model.predict(X_test_transformed)\n",
    "\n",
    "    print('Predicted labels: ', predictions[:15])\n",
    "    print('Actual labels   : ' ,y_test[:15]) \n",
    "    print(classification_report(y_test, predictions))\n",
    "    \n",
    "for model in models:\n",
    "    classification_report_func(model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for checking scores for each model hidden below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "Random Forest has the best accuracy score score with 0.73 accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "with open('random_forest_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset is incomplete in terms of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in numeric_cols:\n",
    "#    test[col] = test[col].replace('_', '')\n",
    "#    test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "\n",
    "\n",
    "#test_transformed = preprocessor.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "\n",
    "# Load the saved model\n",
    "#rf_model = joblib.load('random_forest_model.pkl')\n",
    "\n",
    "# Use the model to predict the target variable for the test data\n",
    "#test_predictions = rf_model.predict(test_transformed)\n",
    "\n",
    "# Print the predictions\n",
    "#print(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21a581218586d279581d34e7b0e3901713820e8aea20b11f3e094bdc5a18c1df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
